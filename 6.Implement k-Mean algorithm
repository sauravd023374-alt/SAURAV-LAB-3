import numpy as np
import matplotlib.pyplot as plt

class KMeans:
    def __init__(self, n_clusters=3, max_iterations=100, random_state=42):
        self.n_clusters = n_clusters
        self.max_iterations = max_iterations
        self.random_state = random_state
        self.centroids = None
        self.labels = None
    
    def fit(self, X):
        np.random.seed(self.random_state)
        # Randomly initialize centroids
        random_indices = np.random.choice(len(X), self.n_clusters, replace=False)
        self.centroids = X[random_indices]
        
        print("K-Means Clustering")
        print(f"Number of clusters: {self.n_clusters}")
        print(f"Max iterations: {self.max_iterations}")
        print(f"\nInitial centroids:")
        for i, centroid in enumerate(self.centroids):
            print(f"Cluster {i}: {centroid}")
        print()
        
        for iteration in range(self.max_iterations):
            self.labels = self._assign_clusters(X)
            
            old_centroids = self.centroids.copy()

            self.centroids = self._update_centroids(X)
            
            if iteration % 10 == 0:
                print(f"Iteration {iteration}:")
                for i, centroid in enumerate(self.centroids):
                    print(f"  Cluster {i}: {centroid}")
            
            # Check convergence
            if np.allclose(old_centroids, self.centroids):
                print(f"\nConverged at iteration {iteration}!")
                break
        
        print(f"\nFinal centroids:")
        for i, centroid in enumerate(self.centroids):
            print(f"Cluster {i}: {centroid}")
        print()
        
        return self
    
    def _assign_clusters(self, X):
        distances = np.zeros((len(X), self.n_clusters))
        
        for i, centroid in enumerate(self.centroids):
            distances[:, i] = np.sqrt(np.sum((X - centroid) ** 2, axis=1))
        
        return np.argmin(distances, axis=1)
    
    def _update_centroids(self, X):
        centroids = np.zeros((self.n_clusters, X.shape[1]))
        
        for i in range(self.n_clusters):
            cluster_points = X[self.labels == i]
            if len(cluster_points) > 0:
                centroids[i] = np.mean(cluster_points, axis=0)
            else:
                # If cluster is empty, keep old centroid
                centroids[i] = self.centroids[i]
        
        return centroids
    
    def predict(self, X):
        return self._assign_clusters(X)
    
    def get_inertia(self, X):
        inertia = 0
        for i in range(self.n_clusters):
            cluster_points = X[self.labels == i]
            inertia += np.sum((cluster_points - self.centroids[i]) ** 2)
        return inertia

# Example: Customer segmentation

print("k-Means Clustering Implementation")
print("Example: Customer Segmentation")


# Create sample data: [income, spending_score]
np.random.seed(42)

# Group 1: Low income, low spending
group1 = np.random.randn(15, 2) * 0.5 + np.array([3, 3])

# Group 2: High income, high spending
group2 = np.random.randn(15, 2) * 0.5 + np.array([7, 7])

# Group 3: High income, low spending
group3 = np.random.randn(15, 2) * 0.5 + np.array([7, 3])

# Combine data
X = np.vstack([group1, group2, group3])

# Apply k-means
kmeans = KMeans(n_clusters=3, max_iterations=100, random_state=42)
kmeans.fit(X)

print("Cluster assignments for first 10 samples:")
print("Sample | Cluster")
print("-" * 30)
for i in range(10):
    print(f"{X[i]} | {kmeans.labels[i]}")

# Calculate inertia
inertia = kmeans.get_inertia(X)
print(f"\nWithin-cluster sum of squares: {inertia:.2f}")

# Count points in each cluster
print("\nCluster sizes:")
for i in range(kmeans.n_clusters):
    count = np.sum(kmeans.labels == i)
    print(f"Cluster {i}: {count} points")
